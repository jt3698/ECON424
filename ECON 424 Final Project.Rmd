---
title: "ECON 424 - Final Project (Winter 2023)"
author: "Submitted by Raphael Shawn Gozali (20805288) and Jason Tedjosoesilo (20801292)"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

```{r, include = FALSE}
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=60), tidy = TRUE)
```



## Questions

For this project, these are the questions that we will be answering:

1. Without any interactions, which covariate(s) affect revenue the most?

2. Are there any certain genres, actors, or keywords that affect revenue the most?

3. If we do interactions between genres, actors, and keywords, are there any particular combination(s) that affect revenue the most?

4. Do people’s preferences on movie genres and actors change over the years/decades?

## Data

In this project, we will be using the Movies dataset from Kaggle: https://www.kaggle.com/datasets/akshaypawar7/millions-of-movies?resource=download. We downloaded this dataset on April 2, 2023 on 2pm EST and continue to work with it locally. This dataset consists of around 723 thousand rows of movies, with their descriptions and details separated into columns. The response variable that we are focusing on from this dataset is the “revenue” column, which shows us the revenue of the movie. The covariates that might be useful from this dataset includes: date published, budget, genres, casts, keywords, and runtime.

Here is the first few rows of the data:

```{r}
data <- read.csv("./movies.csv")
head(data)
```

Before we do some analysis, we will clean the data. First, we will remove unnecessary columns and also data with zero revenues. We are only keeping released movies above 40 minutes as we are not including short movies in the data. This is based on the definition from the Academy of Motion Picture Arts and Sciences, where they define a short film as "an original motion picture that has a running time of 40 minutes or less, including all credits". We also do not include the movies with runtime of value 999. There might also be duplicates in the data, so we need to remove duplicates as well. Since people can add random movies into this database, we try as best as we can to filter those out. To make sure that a movie is legitimate, we filter the movies that do not have any genres, production companies, and credits (all three are empty values).

```{r}
# Only movies that has revenue, is released, and more than 40 minutes long
# Also remove if runtime = 999 and remove the movies with missing genres, production companies, and credits
clean_data <- data[data$revenue > 0 & data$status == "Released" & data$runtime > 40 & data$runtime != 999 & !(data$genres == "" & data$production_companies == "" & data$credits == ""), !names(data) %in% c("overview", "popularity","status", "tagline", "vote_average","vote_count","poster_path","backdrop_path","recommendations")]


# removing empty ID rows
clean_data <- clean_data[!is.na(clean_data$id),]

#resetting row.names
row.names(clean_data) <- NULL

#remove duplicate data
clean_data <- clean_data[!duplicated(clean_data[,1]),]

write.csv(clean_data, file="./movies_filtered.csv", row.names = FALSE)

n <- length(clean_data[,1])

head(clean_data)

hist(log(clean_data$revenue), 
     breaks = quantile(log(clean_data$revenue), p = seq(0,1 , length.out = 21)), 
     freq = FALSE, xlab = "log(revenue)", main = "Histogram of log(revenue) - 5% quantile for each bin")

```

We took this data and use a Python API to calculate the adjusted revenues by adding inflation factors. We calculated all the revenues inflated to April 3, 2023 and include them in the data as a new column called "revenue_adjusted". The data that do not have release_date will have their adjusted revenue be the same as their revenue.

```{r}
clean_data <- read.csv("./movies_adjusted.csv")
head(clean_data)

hist(log(clean_data$revenue_adjusted), 
     breaks = quantile(log(clean_data$revenue_adjusted), p = seq(0,1 , length.out = 21)), 
     freq = FALSE, xlab = "log(revenue_adjusted)", main = "Histogram of log(revenue_adjusted) - 5% quantile for each bin")

n <- length(clean_data[,1])
```

```{r, fig.height=4, fig.width=10}
par(mfrow = c(1,2))
plot(as.Date(clean_data$release_date), log(clean_data$revenue), 
     xlim = c(as.Date("1910-01-01"), as.Date("2025-01-01")), 
     col="blue", lwd = 0.5, xlab = "Release Date", ylab = "Revenue",
     main = "Release Date vs. Revenue")
plot(as.Date(clean_data$release_date), log(clean_data$revenue_adjusted), 
     xlim = c(as.Date("1910-01-01"), as.Date("2025-01-01")), 
     col="blue", lwd = 0.5, xlab = "Release Date", ylab = "Adjusted Revenue",
     main = "Release Date vs. Adjusted Revenue")
```

```{r}
#library(imputeTS)
#dataTS <- ts(data = clean_data$revenue_adjusted, frequency = 5)
```


## Methods

To answer the questions above, we will be doing these methods:

```{r}
library(pdftools)
library(tm)
library(SnowballC)

to_another <- content_transformer(function(x, y, z) gsub(y, z, x))

add_pre <- function(x, pre) {
  ifelse(!is.na(x) & x != "" & nchar(x) > 0 & x != " ", return(paste(pre, x, sep="")), return(x))
}

add_prefix <- content_transformer(add_pre)

#### PRODUCTION COMPANIES
prod_comp <- clean_data$production_companies
docs <- Corpus(VectorSource(prod_comp))
# Remove "-" from the name since it is the separator of the data
docs <- tm_map(docs, to_another, "Metro-Goldwyn-Mayer", "Metro_Goldwyn_Mayer")
docs <- tm_map(docs, to_another, "no_production_companies", "")
docs <- tm_map(docs, to_another, " ", "_")
docs <- tm_map(docs, to_another, "-", " ")
docs <- tm_map(docs, stripWhitespace)
# adding prefix p$ for production_companies
docs <- tm_map(docs, add_prefix, "p$")
docs <- tm_map(docs, to_another, " ", " p$")
dtm <- DocumentTermMatrix(docs)

#get production companies in at least 50 movies
key_pc <- sort(findFreqTerms(dtm, 50))
key_pc
```

```{r}
#### GENRES
genres <- clean_data$genres
docs2 <- Corpus(VectorSource(genres))
docs2 <- tm_map(docs2, to_another, " ", "_")
docs2 <- tm_map(docs2, to_another, "-", " ")
docs2 <- tm_map(docs2, stripWhitespace)
# adding prefix g$ for genres
docs2 <- tm_map(docs2, add_prefix, "g$")
docs2 <- tm_map(docs2, to_another, " ", " g$")
dtm2 <- DocumentTermMatrix(docs2)

#get all genres
key_gen <- sort(findFreqTerms(dtm2, 0))
key_gen
```

```{r}

#### CREDITS
casts <- clean_data$credits
docs3 <- Corpus(VectorSource(casts))
docs3 <- tm_map(docs3, to_another, " ", "_")
# deal with Korean names
docs3 <- tm_map(docs3, to_another, "_([[:alpha:]]+)-([[:lower:]]+)$", "_\\1_\\2")
docs3 <- tm_map(docs3, to_another, "_([[:alpha:]]+)-([[:lower:]]+)-", "_\\1_\\2-")
docs3 <- tm_map(docs3, to_another, "-", " ")
docs3 <- tm_map(docs3, stripWhitespace)
# adding prefix c$ for casts
docs3 <- tm_map(docs3, add_prefix, "c$")
docs3 <- tm_map(docs3, to_another, " ", " c$")
dtm3 <- DocumentTermMatrix(docs3)

#get all casts in at least 50 movies
key_cast <- sort(findFreqTerms(dtm3, 50))

#hard to remove "-" from two-worded names separated by "-"
#so we remove single-word names that comes from them
key_cast <- key_cast[grepl('_', key_cast)]
key_cast
```

```{r}
#### KEYWORDS
keywords <- clean_data$keywords
docs4 <- Corpus(VectorSource(keywords))
docs4 <- tm_map(docs4, to_another, " ", "_")
docs4 <- tm_map(docs4, to_another, "-", " ")
docs4 <- tm_map(docs4, stripWhitespace)
# adding prefix k$ for keywords
docs4 <- tm_map(docs4, add_prefix, "k$")
docs4 <- tm_map(docs4, to_another, " ", " k$")
dtm4 <- DocumentTermMatrix(docs4)

#get all keywords in at least 50 movies
key_keys <- sort(findFreqTerms(dtm4, 50))
key_keys
```

```{r}
#### ORIGINAL LANGUAGE
og_lng <- clean_data$original_language
docs5 <- Corpus(VectorSource(og_lng))
# adding prefix l$ for language
docs5 <- tm_map(docs5, add_prefix, "l$")
docs5 <- tm_map(docs5, to_another, " ", " l$")
dtm5 <- DocumentTermMatrix(docs5)

#get all languages in at least 50 movies
key_lang <- sort(findFreqTerms(dtm5, 50))
key_lang
```

```{r}
X <- cbind(dtm[, key_pc], dtm2[, key_gen], 
           dtm3[, key_cast], dtm4[, key_keys], 
           dtm5[, key_lang])
y <- log(clean_data$revenue)
y_adj <- log(clean_data$revenue_adjusted)
```

```{r}
library(glmnet)
set.seed(424)
model1 <- cv.glmnet(cbind(as.matrix(X), budget = log(clean_data$budget)), y)
coef1 <- coef(model1, s = "lambda.min")
length(coef1[which(coef1 != 0),])
sort(coef1[which(coef1 != 0),1], decreasing = TRUE)
```

```{r}
coef1[c("(Intercept)"),1]
coef_sort <- sort(coef1[,1], decreasing = TRUE)[-1]
head(coef_sort, 10)
tail(coef_sort, 10)
```

```{r}
plot(model1, xvar = "lambda")
```


```{r}
model1_adj <- cv.glmnet(cbind(as.matrix(X), budget = log(clean_data$budget)), y_adj)
coef1_adj <- coef(model1_adj, s = "lambda.min")
length(coef1_adj[which(coef1_adj != 0),])
sort(coef1_adj[which(coef1_adj != 0),1], decreasing = TRUE)
```

```{r}
ic1 <- coef1_adj[c("(Intercept)"),1]
paste("The intercept is ", ic1)
paste("Top 10 variables that positively affect the revenue:")
coef1_adj_sort <- sort(coef1_adj[,1], decreasing = TRUE)[-1]
head(coef1_adj_sort, 10)
paste("Top 10 variables that negatively affects the revenue:")
tail(coef1_adj_sort, 10)
```

```{r}
plot(model1_adj, xvar = "lambda")
```

```{r}
# top 10 of each
key_pc2 <- names(findMostFreqTerms(dtm, 10, INDEX = rep(1, each = n))[[1]])
key_gen2 <- names(findMostFreqTerms(dtm2, 10, INDEX = rep(1, each = n))[[1]])
key_cast2 <- names(findMostFreqTerms(dtm3, 14, INDEX = rep(1, each = n))[[1]])
key_cast2 <- key_cast2[grepl('_', key_cast2)] # 4 of them are single names
key_keys2 <- names(findMostFreqTerms(dtm4, 10, INDEX = rep(1, each = n))[[1]])
int_vars <- c(key_pc2, key_gen2, key_cast2, key_keys2)
inact <- c()
inact_name <- c()
for(i in 1:(length(int_vars)-1)){
  for (j in (i+1):length(int_vars)){
    a = as.matrix(X[,int_vars[i]])
    b = as.matrix(X[,int_vars[j]])
    var_name = paste(int_vars[i],".",int_vars[j])
    v = a*b
    inact <- cbind(inact, v)
    inact_name <- c(inact_name, var_name)
  }
}

df_inact = data.frame(inact)
colnames(df_inact) <- inact_name
```


```{r}

X2 <- cbind(dtm[, key_pc], dtm2[, key_gen], 
            dtm3[, key_cast], dtm4[, key_keys], 
            dtm5[, key_lang], df_inact)
model2 <- cv.glmnet(cbind(as.matrix(X2), 
            budget = log(clean_data$budget)), y_adj)
coef2 <- coef(model2, s = "lambda.min")
sort(coef2[which(coef2 != 0),1], decreasing = TRUE)

```



```{r}
ic2 <- coef2[c("(Intercept)"),1]
paste("The intercept is ", ic2)
paste("Top 10 variables that positively affect the revenue:")
coef2_sort <- sort(coef2[,1], decreasing = TRUE)[-1]
head(coef2_sort, 10)
paste("Top 10 variables that negatively affects the revenue:")
tail(coef2_sort, 10)
```

```{r}
plot(model2, xvar = "lambda")
```

```{r}
clean_data$year <- format(as.Date(clean_data$release_date), format = "%Y")
clean_data$decades <- floor(as.numeric(clean_data$year) / 10) * 10
df_list <- split(clean_data, clean_data$decades)
```


```{r}

coefs <- c()

for (df in df_list){
  #### PRODUCTION COMPANIES
  sub_prod_comp <- df$production_companies
  sub_docs <- Corpus(VectorSource(sub_prod_comp))
  # Remove "-" from the name since it is the splitter symbol of the data
  sub_docs <- tm_map(sub_docs, to_another, "Metro-Goldwyn-Mayer", "Metro_Goldwyn_Mayer")
  sub_docs <- tm_map(sub_docs, to_another, "no_production_companies", "")
  sub_docs <- tm_map(sub_docs, to_another, " ", "_")
  sub_docs <- tm_map(sub_docs, to_another, "-", " ")
  sub_docs <- tm_map(sub_docs, stripWhitespace)
  # adding prefix p$ for production_companies
  sub_docs <- tm_map(sub_docs, add_prefix, "p$")
  sub_docs <- tm_map(sub_docs, to_another, " ", " p$")
  sub_dtm <- DocumentTermMatrix(sub_docs)

  #get top 10 production companies
  sub_key_pc <- findMostFreqTerms(sub_dtm, 10, INDEX = rep(1, each = length(df[,1])))
  #print(sub_key_pc)
  
  #### GENRES
  sub_genres <- df$genres
  sub_docs2 <- Corpus(VectorSource(sub_genres))
  sub_docs2 <- tm_map(sub_docs2, to_another, " ", "_")
  sub_docs2 <- tm_map(sub_docs2, to_another, "-", " ")
  sub_docs2 <- tm_map(sub_docs2, stripWhitespace)
  # adding prefix g$ for genres
  sub_docs2 <- tm_map(sub_docs2, add_prefix, "g$")
  sub_docs2 <- tm_map(sub_docs2, to_another, " ", " g$")
  sub_dtm2 <- DocumentTermMatrix(sub_docs2)

  #get top 10 genres
  sub_key_gen <- findMostFreqTerms(sub_dtm2, 10, INDEX = rep(1, each = length(df[,1])))
  #sub_key_gen
  
  #### CREDITS
  sub_casts <- df$credits
  sub_docs3 <- Corpus(VectorSource(sub_casts))
  sub_docs3 <- tm_map(sub_docs3, to_another, " ", "_")
  # deal with Korean names
  sub_docs3 <- tm_map(sub_docs3, to_another, "_([[:alpha:]]+)-([[:lower:]]+)$", "_\\1_\\2")
  sub_docs3 <- tm_map(sub_docs3, to_another, "_([[:alpha:]]+)-([[:lower:]]+)-", "_\\1_\\2-")
  sub_docs3 <- tm_map(sub_docs3, to_another, "-", " ")
  sub_docs3 <- tm_map(sub_docs3, stripWhitespace)
  # adding prefix c$ for casts
  sub_docs3 <- tm_map(sub_docs3, add_prefix, "c$")
  sub_docs3 <- tm_map(sub_docs3, to_another, " ", " c$")
  sub_dtm3 <- DocumentTermMatrix(sub_docs3)

  #get top 10 casts
  sub_key_cast <- findMostFreqTerms(sub_dtm3, 10, INDEX = rep(1, each = length(df[,1])))
  
  #### KEYWORDS
  sub_keywords <- df$keywords
  sub_docs4 <- Corpus(VectorSource(sub_keywords))
  sub_docs4 <- tm_map(sub_docs4, to_another, " ", "_")
  sub_docs4 <- tm_map(sub_docs4, to_another, "-", " ")
  sub_docs4 <- tm_map(sub_docs4, stripWhitespace)
  # adding prefix k$ for keywords
  sub_docs4 <- tm_map(sub_docs4, add_prefix, "k$")
  sub_docs4 <- tm_map(sub_docs4, to_another, " ", " k$")
  sub_dtm4 <- DocumentTermMatrix(sub_docs4)

  #get top 10 keywords
  sub_key_keys <- findMostFreqTerms(sub_dtm4, 10, INDEX = rep(1, each = length(df[,1])))
  #sub_key_keys
  
  #### ORIGINAL LANGUAGE
  sub_og_lng <- df$original_language
  sub_docs5 <- Corpus(VectorSource(sub_og_lng))
  # adding prefix l$ for language
  sub_docs5 <- tm_map(sub_docs5, add_prefix, "l$")
  sub_docs5 <- tm_map(sub_docs5, to_another, " ", " l$")
  sub_dtm5 <- DocumentTermMatrix(sub_docs5)

  #get all languages in at least 50 movies
  sub_key_lang <- findMostFreqTerms(sub_dtm5, 10, INDEX = rep(1, each = length(df[,1])))
  #sub_key_lang
  
  sub_X <- cbind(sub_dtm[, names(sub_key_pc[[1]])], sub_dtm2[, names(sub_key_gen[[1]])], sub_dtm3[, names(sub_key_cast[[1]])], sub_dtm4[, names(sub_key_keys[[1]])], sub_dtm5[, names(sub_key_lang[[1]])])
  sub_y <- log(df$revenue_adjusted)
  sub_model1 <- cv.glmnet(cbind(as.matrix(sub_X), budget = log(df$budget)), sub_y)
  sub_coef1 <- coef(sub_model1, s = "lambda.min")
  sub_coef_sort <- sort(sub_coef1[which(sub_coef1 != 0),1], decreasing = TRUE)
  coefs <- c(coefs, sub_coef_sort)
  
  print(df$decades[1])
  print(sub_coef_sort)
  
}

#coefs

```

4. Get the words from step 3 and create interactions between them. Include these interactions as covariates in the regression.

5. Separate the data by year/decade published and do the modelling using LASSO on these subgroups and see whether the model changes over time.

## Results

From this project, we hope to get a good model based on this data where revenue is based only on a small number of covariates, i.e a small number of elasticities. We also hope to get interesting keywords and interactions between genres and casts that can affect revenue of the movie. Changes in people’s preferences of the movies over the years/decades are also expected here, since the trends between generations are likely to be different.
